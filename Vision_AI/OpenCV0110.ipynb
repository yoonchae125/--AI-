{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BOW\n",
    ": 빈도를 세서 자주 나타나는 낱말로 문서 카테고리를 분리 한다.\n",
    "ex) 훈련, 사격, 작전 => 군용 문서 / 수술, 환자, 감염, 상처 => 의료 문서\n",
    "\n",
    "STEP\n",
    "* (1) 디스크립터 계산\n",
    "* (2) K-MEANS 알고리즘으로 군집화 \n",
    "    - 이미지별 특징끼리 분류됨 \n",
    "* (3) 특징들을 히스토그램화 시킴 => 특정범위에 있으면 해당 물체로 분류"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train\n",
    "    - 먼저 ['airplanes', 'Motorbikes' ]에서 학습 후 아래의 Test 행에서 확인 후 \n",
    "    - 클러스트 개수를 제외한 변수 변경해서 실행해볼것"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding descriptor to BOWTrainer...\n",
      "\tairplanes 800/800(100.00%)\n",
      "\tMotorbikes 798/798(100.00%)\n",
      "Adding descriptor completed...\n",
      "Starting Dictionary clustering(50)...         It will take several time...\n",
      "Dictionary Clustering completed...dictionary shape: (50, 128)\n",
      "Compute histogram training set...(100.00%)\n",
      "svm items 1598 50\n",
      "svm training...\n",
      "svm training completed.\n",
      "Training Elapsed: 00:04:30\n",
      "Accuracy(Self)\n",
      "\tairplanes: 96.38 %\n",
      "\tMotorbikes: 95.36 %\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os, glob, time\n",
    "\n",
    "# 각종 변수 선언---①\n",
    "startT = time.time()                        # 소요시간 측정을 위한 시간 저장\n",
    "categories =  ['airplanes', 'Motorbikes' ]  # 카테고리 이름 \n",
    "dictionary_size = 50                        # 사전 크기, 클러스터 갯수 \n",
    "base_path = \"img/101_ObjectCategories/\"  # 학습 이미지 기본 경로 \n",
    "dict_file = 'plane_bike_dict.npy'         # 사전 객체 저장할 파일 이름 \n",
    "svm_model_file = 'plane_bike_svm.xml'     # SVM 모델 객체 저장할 파일 이름 \n",
    "\n",
    "# 추출기와 BOW 객체 생성 --- ②\n",
    "detector = cv2.xfeatures2d.SIFT_create()    # 추출기로 SIFT 생성 \n",
    "matcher = cv2.BFMatcher(cv2.NORM_L2)        # 매칭기로 BF 생성\n",
    "bowTrainer = cv2.BOWKMeansTrainer(dictionary_size) # KMeans로 구현된 BWOTrainer 생성\n",
    "bowExtractor = cv2.BOWImgDescriptorExtractor(detector, matcher) # 히스토그램 계산할 BOW추출기 생성\n",
    "\n",
    "# 특징 디스크립터를 KMeansTrainer에 추가---③\n",
    "train_paths = []                            # 훈련에 사용할 모든 이미지 경로 \n",
    "train_labels = []                           # 학습 데이타 레이블\n",
    "print('Adding descriptor to BOWTrainer...')\n",
    "for idx, category in enumerate(categories): # 카테고리 순회\n",
    "    dir_path = base_path + category          \n",
    "    img_paths = glob.glob(dir_path +'/*.jpg') \n",
    "    img_len = len(img_paths)\n",
    "    for i, img_path in enumerate(img_paths): # 카테고리 내의 모든 이미지 파일 순회\n",
    "        train_paths.append(img_path)        \n",
    "        train_labels.append(idx)            # 학습 데이타 레이블, 0 또는 1 \n",
    "        img = cv2.imread(img_path)          \n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        # 특징점과 특징 디스크립터 추출 및 bowTrainer에 추가 ---④\n",
    "        kpt, desc= detector.detectAndCompute(gray, None) \n",
    "        bowTrainer.add(desc)                \n",
    "        print('\\t%s %d/%d(%.2f%%)' \\\n",
    "              %(category,i+1, img_len, (i+1)/img_len*100), end='\\r')\n",
    "    print()\n",
    "print('Adding descriptor completed...')\n",
    "\n",
    "# KMeans 클러스터로 군집화하여 시각 사전 생성 및 저장---⑤\n",
    "print('Starting Dictionary clustering(%d)... \\\n",
    "        It will take several time...'%dictionary_size)\n",
    "dictionary = bowTrainer.cluster() # 군집화로 시각 사전 생성  \n",
    "np.save(dict_file, dictionary)    # 시각 사전 데이타(넘파일)를 파일로 저장\n",
    "print('Dictionary Clustering completed...dictionary shape:',dictionary.shape)\n",
    "\n",
    "# 시각 사전과 모든 이미지의 매칭점으로 히스토그램 계산---⑥\n",
    "bowExtractor.setVocabulary(dictionary)      # bowExtractor에 시각 사전 셋팅 \n",
    "train_desc = []                             # 학습 데이타 \n",
    "for i, path in enumerate(train_paths):      # 모든 학습 대상 이미지 순회\n",
    "    img = cv2.imread(path)                  # 이미지 읽기 \n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) \n",
    "    # 매칭점에 대한 히스토그램 계산 --- ⑦\n",
    "    hist = bowExtractor.compute(gray, detector.detect(gray)) \n",
    "    train_desc.extend(hist)                 \n",
    "    print('Compute histogram training set...(%.2f%%)'\\\n",
    "                    %((i+1)/len(train_paths)*100),end='\\r')\n",
    "print(\"\\nsvm items\", len(train_desc), len(train_desc[0]))\n",
    "\n",
    "# 히스토그램을 학습데이타로 SVM 훈련 및 모델 저장---⑧\n",
    "print('svm training...')\n",
    "svm = cv2.ml.SVM_create()\n",
    "svm.trainAuto(np.array(train_desc), cv2.ml.ROW_SAMPLE, np.array(train_labels))\n",
    "svm.save(svm_model_file)\n",
    "print('svm training completed.')\n",
    "print('Training Elapsed: %s'\\\n",
    "        %time.strftime('%H:%M:%S', time.gmtime(time.time()-startT)))\n",
    "\n",
    "# 원래의 이미지로 테스트 --- ⑨\n",
    "print(\"Accuracy(Self)\")\n",
    "for label, dir_name in enumerate(categories):\n",
    "    labels = []\n",
    "    results = []\n",
    "    img_paths = glob.glob(base_path + '/'+dir_name +'/*.*')\n",
    "    for img_path in img_paths:\n",
    "        labels.append(label)\n",
    "        img = cv2.imread(img_path)\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        feature = bowExtractor.compute(gray, detector.detect(gray))\n",
    "        ret, result = svm.predict(feature)\n",
    "        resp = result[0][0]\n",
    "        results.append(resp)\n",
    "\n",
    "    labels = np.array(labels)\n",
    "    results = np.array(results)\n",
    "    err = (labels != results)\n",
    "    err_mean = err.mean()\n",
    "    print('\\t%s: %.2f %%' % (dir_name, (1 - err_mean)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "categories =  ['airplanes', 'Motorbikes' ]\n",
    "dict_file = 'plane_bike_dict.npy'\n",
    "#dict_file = './plane_bike_dict_4000.npy'\n",
    "svm_model_file = 'plane_bike_svm.xml'\n",
    "#svm_model_file = './plane_bike_svm_4000.xml'\n",
    "\n",
    "# 테스트 할 이미지 경로 --- ①\n",
    "imgs = ['img/aircraft.jpg','img/jetstar.jpg', \n",
    "        'img/motorcycle.jpg', 'img/motorbike.jpg']\n",
    "\n",
    "# 특징 추출기(SIFT) 생성 ---②\n",
    "detector = cv2.xfeatures2d.SIFT_create()\n",
    "# BOW 추출기 생성 및 사전 로딩 ---③\n",
    "bowextractor = cv2.BOWImgDescriptorExtractor(detector, \\\n",
    "                                cv2.BFMatcher(cv2.NORM_L2))\n",
    "bowextractor.setVocabulary(np.load(dict_file))\n",
    "# 훈련된 모델 읽어서 SVM 객체 생성 --- ④\n",
    "svm  = cv2.ml.SVM_load(svm_model_file)\n",
    "\n",
    "# 4개의 이미지 테스트 \n",
    "for i, path in enumerate(imgs):\n",
    "    img = cv2.imread(path)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    # 테스트 이미지에서 BOW 히스토그램 추출 ---⑤\n",
    "    hist = bowextractor.compute(gray, detector.detect(gray))\n",
    "    # SVM 예측 ---⑥\n",
    "    ret, result = svm.predict(hist)\n",
    "    # 결과 표시 \n",
    "    name = categories[int(result[0][0])]\n",
    "    txt, base = cv2.getTextSize(name, cv2.FONT_HERSHEY_PLAIN, 2, 3)\n",
    "    x,y = 10, 50\n",
    "    cv2.rectangle(img, (x,y-base-txt[1]), (x+txt[0], y+txt[1]), (30,30,30), -1)\n",
    "    cv2.putText(img, name, (x,y), cv2.FONT_HERSHEY_PLAIN, \\\n",
    "                                 2, (0,255,0), 2, cv2.LINE_AA)\n",
    "    cv2.imshow(path, img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Histogram of Oriented Gradient(HOG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(1) 보행자 검출을 목적으로 만들어 졌다. \n",
    "(2) SIFT, SURF, ORB 등에 비해 전체적인 모양을 특징으로 표현하기 용이하다. \n",
    "\n",
    "순서\n",
    "1. 인식하고자 하는 영역을 자른다. (window)\n",
    "2. 소벨 필터를 이용해서 엣지의 기울기 gx, gy를 구한다.  \n",
    "3. 8 x 8셀 나누어 기울기의 방향과 크기를 계산한다. \n",
    "4. 2배 크기의 블록으로 셀을 노멀라이즈 \n",
    "\n",
    "=> 픽셀 차이를 이용해서 기울기를 구한다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nimg = cv2.imread('img.png')\\nimg =  np.float(img)\\n\\ngx = cv.Sobel(img, cv.CV_32F, 1, 0)\\ngy = cv.Sobel(img, cv.CV_32F, 0, 1)\\nmagnitude, angle = cv.cartToPolar(gx, gy)\\n    - magnitude : 크기 \\n    - angle : 기울기의 방향\\n\\n\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\"\"\"\n",
    "img = cv2.imread('img.png')\n",
    "img =  np.float(img)\n",
    "\n",
    "gx = cv.Sobel(img, cv.CV_32F, 1, 0)\n",
    "gy = cv.Sobel(img, cv.CV_32F, 0, 1)\n",
    "magnitude, angle = cv.cartToPolar(gx, gy)\n",
    "    - magnitude : 크기 \n",
    "    - angle : 기울기의 방향\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HOG - SVM 보행자 검출\n",
    "* cv2.HOGDescriptor_getDefaultPeopleDetector() : 64 x 128 윈도 크기로 훈련된 모델 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Toggle Space-bar to change mode.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "# default 디덱터를 위한 HOG 객체 생성 및 설정--- ①\n",
    "hogdef = cv2.HOGDescriptor()\n",
    "hogdef.setSVMDetector(cv2.HOGDescriptor_getDefaultPeopleDetector())\n",
    "\n",
    "# dailer 디덱터를 위한 HOG 객체 생성 및 설정--- ②\n",
    "hogdaim  = cv2.HOGDescriptor((48,96), (16,16), (8,8), (8,8), 9)\n",
    "hogdaim.setSVMDetector(cv2.HOGDescriptor_getDaimlerPeopleDetector())\n",
    "\n",
    "cap = cv2.VideoCapture('./img/walking.avi')\n",
    "mode = True  # 모드 변환을 위한 플래그 변수 \n",
    "print('Toggle Space-bar to change mode.')\n",
    "while cap.isOpened():\n",
    "    ret, img = cap.read()\n",
    "    if ret :\n",
    "        if mode:\n",
    "            # default 디텍터로 보행자 검출 --- ③\n",
    "            found, _ = hogdef.detectMultiScale(img)\n",
    "            for (x,y,w,h) in found:\n",
    "                cv2.rectangle(img, (x,y), (x+w, y+h), (0,255,255))\n",
    "        else:\n",
    "            # daimler 디텍터로 보행자 검출 --- ④\n",
    "            found, _ = hogdaim.detectMultiScale(img)\n",
    "            for (x,y,w,h) in found:\n",
    "                cv2.rectangle(img, (x,y), (x+w, y+h), (0,255,0))\n",
    "        cv2.putText(img, 'Detector:%s'%('Default' if mode else 'Daimler'), \\\n",
    "                        (10,50 ), cv2.FONT_HERSHEY_DUPLEX,1, (0,255,0),1)\n",
    "        cv2.imshow('frame', img)\n",
    "        key = cv2.waitKey(1) \n",
    "        if key == 27:\n",
    "            break\n",
    "        elif key == ord(' '):\n",
    "            mode = not mode\n",
    "    else:\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 한니발 마스크"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# 마스크 이미지 읽기 \n",
    "face_mask = cv2.imread('img/mask_hannibal.png')\n",
    "h_mask, w_mask = face_mask.shape[:2]\n",
    "# 얼굴 검출기 생성\n",
    "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_alt.xml')\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\t# 얼굴 영역 검출\n",
    "    face_rects = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "    for (x,y,w,h) in face_rects:\n",
    "        if h > 0 and w > 0:\n",
    "        \t\t# 마스크 위치 보정\n",
    "            x = int(x + 0.1*w)\n",
    "            y = int(y + 0.4*h)\n",
    "            w = int(0.8 * w)\n",
    "            h = int(0.8 * h)\n",
    "\n",
    "            frame_roi = frame[y:y+h, x:x+w]\n",
    "            # 마스크 이미지를 얼굴 크기에 맞게 조정 \n",
    "            face_mask_small = cv2.resize(face_mask, (w, h), \\\n",
    "                                interpolation=cv2.INTER_AREA)\n",
    "\t\t\t# 마스크 이미지 합성\n",
    "            gray_mask = cv2.cvtColor(face_mask_small, cv2.COLOR_BGR2GRAY)\n",
    "            ret, mask = cv2.threshold(gray_mask, 50, 255, cv2.THRESH_BINARY)\n",
    "            mask_inv = cv2.bitwise_not(mask)\n",
    "            masked_face = cv2.bitwise_and(face_mask_small, face_mask_small,\\\n",
    "                                         mask=mask)\n",
    "            masked_frame = cv2.bitwise_and(frame_roi, frame_roi, mask=mask_inv)\n",
    "            frame[y:y+h, x:x+w] = cv2.add(masked_face, masked_frame)\n",
    "\n",
    "    cv2.imshow('Hanibal Mask', frame)\n",
    "    if cv2.waitKey(1) == 27:\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(3.4.2) C:\\projects\\opencv-python\\opencv\\modules\\objdetect\\src\\cascadedetect.cpp:1698: error: (-215:Assertion failed) !empty() in function 'cv::CascadeClassifier::detectMultiScale'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-e148685b7e87>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mimg2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mframe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     \u001b[1;31m# 얼굴 검출해서 오목/볼록 렌즈 효과로 왜곡 적용\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 60\u001b[1;33m     \u001b[0mfaces\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfindFaces\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     61\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mface\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfaces\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m         \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mface\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-9-e148685b7e87>\u001b[0m in \u001b[0;36mfindFaces\u001b[1;34m(img)\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mfindFaces\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m     \u001b[0mgray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCOLOR_BGR2GRAY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m     \u001b[0mfaces\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mface_cascade\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetectMultiScale\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m     \u001b[0mface_coords\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mh\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfaces\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(3.4.2) C:\\projects\\opencv-python\\opencv\\modules\\objdetect\\src\\cascadedetect.cpp:1698: error: (-215:Assertion failed) !empty() in function 'cv::CascadeClassifier::detectMultiScale'\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# 얼굴과 눈동자 검출기 생성\n",
    "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "eye_cascade = cv2.CascadeClassifier('haarcascade_eye.xml')\n",
    "\n",
    "# 렌즈 왜곡 효과 함수\n",
    "def distortedMap(rows, cols, type=0):\n",
    "    map_y, map_x = np.indices((rows, cols), dtype=np.float32)\n",
    "    # 렌즈 효과\n",
    "    ## 렌즈 효과, 중심점 이동\n",
    "    map_lenz_x = (2*map_x - cols)/cols\n",
    "    map_lenz_y = (2*map_y - rows)/rows\n",
    "    ## 렌즈 효과, 극좌표 변환\n",
    "    r, theta = cv2.cartToPolar(map_lenz_x, map_lenz_y)\n",
    "    if type==0:\n",
    "    ## 볼록 렌즈 효과 매핑 좌표 연산\n",
    "        r[r< 1] = r[r<1] **3  \n",
    "    else:\n",
    "    ## 오목 렌즈 효과 매핑 좌표 연산\n",
    "        r[r< 1] = r[r<1] **0.5\n",
    "    ## 렌즈 효과, 직교 좌표 복원\n",
    "    mapx, mapy = cv2.polarToCart(r, theta)\n",
    "    ## 렌즈 효과, 좌상단 좌표 복원\n",
    "    mapx = ((mapx + 1)*cols)/2\n",
    "    mapy = ((mapy + 1)*rows)/2\n",
    "    return (mapx, mapy)\n",
    "\n",
    "# 얼굴 검출 함수\n",
    "def findFaces(img):\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(gray)\n",
    "    face_coords = []\n",
    "    for (x,y,w,h) in faces:\n",
    "        face_coords.append((x, y, w, h))\n",
    "    return face_coords\n",
    "# 눈 검출 함수\n",
    "def findEyes(img):\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(gray)\n",
    "    eyes_coords = []\n",
    "    for (x,y,w,h) in faces:\n",
    "        roi_gray = gray[y:y+h, x:x+w]\n",
    "        eyes = eye_cascade.detectMultiScale(roi_gray )\n",
    "        for(ex,ey,ew,eh) in eyes:\n",
    "            eyes_coords.append((ex+x,ey+y,ew,eh))\n",
    "    return eyes_coords\n",
    "\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "cap.set(cv2.CAP_PROP_FRAME_WIDTH, 480)\n",
    "cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 320)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    img1 = frame.copy()\n",
    "    img2 = frame.copy()\n",
    "    # 얼굴 검출해서 오목/볼록 렌즈 효과로 왜곡 적용\n",
    "    faces = findFaces(frame)\n",
    "    for face in faces:\n",
    "        x,y,w,h = face\n",
    "        mapx, mapy = distortedMap(w,h, 1)\n",
    "        roi = img1[y:y+h, x:x+w]\n",
    "        convex = cv2.remap(roi,mapx,mapy,cv2.INTER_LINEAR)\n",
    "        img1[y:y+h, x:x+w] = convex\n",
    "    # 눈 영역 검출해서 볼록 렌즈 효과로 왜곡 적용\n",
    "    eyes = findEyes(frame)\n",
    "    for eye in eyes :\n",
    "        x,y,w,h = eye\n",
    "        mapx, mapy = distortedMap(w,h)\n",
    "        roi = img2[y:y+h, x:x+w]\n",
    "        convex = cv2.remap(roi,mapx,mapy,cv2.INTER_LINEAR)\n",
    "        img2[y:y+h, x:x+w] = convex\n",
    "    # 하나의 이미지로 병합해서 출력\n",
    "    merged = np.hstack((frame, img1, img2))\n",
    "    cv2.imshow('Face Distortion', merged)\n",
    "    if cv2.waitKey(1) == 27:\n",
    "        break\n",
    "cv2.destroyAllWindows()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
