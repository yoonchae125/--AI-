{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruce0809\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:645: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\bruce0809\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:44: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "C:\\Users\\bruce0809\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:645: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\bruce0809\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:46: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "bank_df = pd.read_csv('bank.csv')\n",
    "del bank_df['previous']\n",
    "del bank_df['campaign']\n",
    "del bank_df['poutcome']\n",
    "del bank_df['pdays']\n",
    "del bank_df['month']\n",
    "\n",
    "# 2가지 범주 숫자화\n",
    "yesno_mapping = {'no':0, 'yes':1}\n",
    "\n",
    "bank_df['deposit'] = bank_df['deposit'].map(yesno_mapping)\n",
    "bank_df['default'] = bank_df['default'].map(yesno_mapping)\n",
    "bank_df['housing'] = bank_df['housing'].map(yesno_mapping)\n",
    "bank_df['loan'] = bank_df['loan'].map(yesno_mapping)\n",
    "\n",
    "# 3~4가지 범주 숫자화\n",
    "contact_mapping = {'cellular':1, 'unknown':2, 'telephone':3}\n",
    "bank_df['contact'] = bank_df['contact'].map(contact_mapping)\n",
    "marital_mapping = {'married':1, 'single':2, 'divorced':3}\n",
    "bank_df['marital'] = bank_df['marital'].map(marital_mapping)\n",
    "education_mapping = {'secondary':1, 'tertiary':2, 'primary':3, 'unknown':4}\n",
    "bank_df['education'] = bank_df['education'].map(education_mapping)\n",
    "\n",
    "# 나이 범주화\n",
    "bank_df.loc[ bank_df['age'] <= 16, 'age'] = 0,\n",
    "bank_df.loc[(bank_df['age'] > 16) & (bank_df['age'] <= 32), 'age'] = 1,\n",
    "bank_df.loc[(bank_df['age'] > 32) & (bank_df['age'] <= 48), 'age'] = 2,\n",
    "bank_df.loc[(bank_df['age'] > 48) & (bank_df['age'] <= 64), 'age'] = 3,\n",
    "bank_df.loc[ bank_df['age'] > 64, 'age'] = 4\n",
    "\n",
    "list_job = bank_df['job'].unique()\n",
    "job_mapping = {}\n",
    "for index in range(len(list_job)):\n",
    "    job_mapping[list_job[index]] = index\n",
    "    \n",
    "bank_df['job'] = bank_df['job'].map(job_mapping)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(bank_df[['balance']])\n",
    "bank_df['balance'] = scaler.transform(bank_df[['balance']])\n",
    "scaler.fit(bank_df[['duration']])\n",
    "bank_df['duration'] = scaler.transform(bank_df[['duration']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델링 전 데이터 나누기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = bank_df['deposit']\n",
    "data = bank_df.iloc[:, 0:-1]\n",
    "\n",
    "x_data = np.array(data)\n",
    "y_data = np.array(target)\n",
    "y_data = np.reshape(y_data, [len(y_data), 1])\n",
    "\n",
    "from sklearn import preprocessing\n",
    "enc = preprocessing.OneHotEncoder(categories='auto')\n",
    "enc.fit(y_data)\n",
    "y_data = enc.transform(y_data) \n",
    "y_data = y_data.toarray()\n",
    "y_data\n",
    "\n",
    "from sklearn import model_selection\n",
    "train_data, test_data, train_label, test_label = model_selection.train_test_split(x_data, y_data,\n",
    "                                                                                 test_size=0.3,\n",
    "                                                                                 random_state=0)\n",
    "\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import layers\n",
    "import os\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델링 작업"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "111"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = tf.placeholder(tf.float32, [None, 11])  # number of X_data's columns\n",
    "Y = tf.placeholder(tf.float32, [None, 2])  # number of Y_data's columns (one-hot vector)\n",
    "bn_sign = tf.placeholder(tf.bool)\n",
    "\n",
    "# contrib는 2점대 버전에서 없어질 함수\n",
    "L1 = layers.dense(X, 256, activation=tf.nn.relu, kernel_initializer=tf.keras.initializers.he_normal())\n",
    "L1 = tf.layers.batch_normalization(L1, training=bn_sign)\n",
    "L1 = layers.dropout(L1, rate=0.2, training=bn_sign)\n",
    "\n",
    "L2 = layers.dense(L1, 256, activation=tf.nn.relu, kernel_initializer=tf.keras.initializers.he_normal())\n",
    "L2 = tf.layers.batch_normalization(L2, training=bn_sign)\n",
    "L2 = layers.dropout(L2, rate=0.2, training=bn_sign)\n",
    "\n",
    "model = layers.dense(L2, 2, activation=None)\n",
    "\n",
    "cost = tf.losses.softmax_cross_entropy(Y, model)\n",
    "\n",
    "update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "\n",
    "with tf.control_dependencies(update_ops):\n",
    "    optimizer = tf.train.AdamOptimizer(1e-2).minimize(cost)\n",
    "    \n",
    "is_correct = tf.equal(tf.argmax(model, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(is_correct, tf.float32))\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "batch_size = 100\n",
    "total_batch = len(bank_df) // batch_size\n",
    "total_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 || Avg. cost = 0.458 || Training accuracy : 0.800 || Test accuracy : 0.751\n",
      "Epoch: 0002 || Avg. cost = 0.370 || Training accuracy : 0.740 || Test accuracy : 0.729\n",
      "Epoch: 0003 || Avg. cost = 0.361 || Training accuracy : 0.750 || Test accuracy : 0.764\n",
      "Epoch: 0004 || Avg. cost = 0.355 || Training accuracy : 0.800 || Test accuracy : 0.775\n",
      "Epoch: 0005 || Avg. cost = 0.343 || Training accuracy : 0.820 || Test accuracy : 0.778\n",
      "Epoch: 0006 || Avg. cost = 0.340 || Training accuracy : 0.850 || Test accuracy : 0.781\n",
      "Epoch: 0007 || Avg. cost = 0.336 || Training accuracy : 0.770 || Test accuracy : 0.783\n",
      "Epoch: 0008 || Avg. cost = 0.345 || Training accuracy : 0.730 || Test accuracy : 0.760\n",
      "Epoch: 0009 || Avg. cost = 0.339 || Training accuracy : 0.760 || Test accuracy : 0.749\n",
      "Epoch: 0010 || Avg. cost = 0.331 || Training accuracy : 0.760 || Test accuracy : 0.721\n",
      "Epoch: 0011 || Avg. cost = 0.331 || Training accuracy : 0.850 || Test accuracy : 0.741\n",
      "Epoch: 0012 || Avg. cost = 0.331 || Training accuracy : 0.750 || Test accuracy : 0.773\n",
      "Epoch: 0013 || Avg. cost = 0.327 || Training accuracy : 0.770 || Test accuracy : 0.778\n",
      "Epoch: 0014 || Avg. cost = 0.328 || Training accuracy : 0.850 || Test accuracy : 0.784\n",
      "Epoch: 0015 || Avg. cost = 0.326 || Training accuracy : 0.730 || Test accuracy : 0.761\n",
      "Learning process is completed!\n"
     ]
    }
   ],
   "source": [
    "def shuffle_batch(X, Y, batch_size):\n",
    "    rnd_idx = np.random.permutation(len(X))\n",
    "    n_batches = len(X) // batch_size\n",
    "    for batch_idx in np.array_split(rnd_idx, n_batches):\n",
    "        X_batch, Y_batch = X[batch_idx], Y[batch_idx]\n",
    "        yield X_batch, Y_batch\n",
    "        \n",
    "for epoch in range(15):\n",
    "    train_cp = []  # Training accuracy 를 동시에 출력해보도록 합니다.\n",
    "    total_cost = 0\n",
    "    test_cp = []\n",
    "    for batch_xs, batch_ys in shuffle_batch(train_data, train_label, batch_size): \n",
    "        \n",
    "        _, cost_val = sess.run([optimizer, cost], feed_dict={X: batch_xs, Y: batch_ys, bn_sign: True})\n",
    "        \n",
    "        # 매 Epoch마다 Total cost를 출력합니다.\n",
    "        total_cost += cost_val # cost\n",
    "\n",
    "        # 매 Epoch마다 Training accuracy를 출력합니다. (bn_sign을 False로 바꾸어 training mode가 아닌 inference mode로 실행합니다.)\n",
    "        train_cp = sess.run([is_correct], feed_dict={X: batch_xs, Y: batch_ys, bn_sign: False}) # Training accuracy\n",
    "        test_cp =sess.run(accuracy, feed_dict={ X: test_data, Y: test_label, bn_sign: False})\n",
    "\n",
    "    print('Epoch:', '%04d' % (epoch + 1), \n",
    "          '|| Avg. cost =', '{:.3f}'.format(total_cost / total_batch), # cost\n",
    "          '|| Training accuracy : {:.3f}'.format(np.mean(train_cp)),   # Training accuracy\n",
    "          '|| Test accuracy : {:.3f}'.format(test_cp)) \n",
    "\n",
    "print('Learning process is completed!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
